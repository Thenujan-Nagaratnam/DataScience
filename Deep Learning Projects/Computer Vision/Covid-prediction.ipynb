{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COVID-19 Prediction","metadata":{}},{"cell_type":"markdown","source":"### Import necessary libraries","metadata":{}},{"cell_type":"code","source":"pip install opencv-python","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:00.102040Z","iopub.execute_input":"2023-09-29T08:38:00.102415Z","iopub.status.idle":"2023-09-29T08:38:09.552340Z","shell.execute_reply.started":"2023-09-29T08:38:00.102390Z","shell.execute_reply":"2023-09-29T08:38:09.551225Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.8.0.76)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:09.554754Z","iopub.execute_input":"2023-09-29T08:38:09.555173Z","iopub.status.idle":"2023-09-29T08:38:19.012262Z","shell.execute_reply.started":"2023-09-29T08:38:09.555118Z","shell.execute_reply":"2023-09-29T08:38:19.010965Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (3.45.2)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.1.1)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.98.0)\nRequirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.1)\nRequirement already satisfied: gradio-client==0.5.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.5.3)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.16.4)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.12.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.2)\nRequirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.23.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.0.2)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.10.9)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.6)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0)\nRequirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.31.0)\nRequirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.0)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.6.3)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\nRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (11.0.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.5.3->gradio) (2023.9.0)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.7.22)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\nRequirement already satisfied: httpcore<0.19.0,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (0.18.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio) (3.7.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio) (1.1.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm.auto import tqdm\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport albumentations\nimport cv2\nimport os\nfrom typing import Dict, Tuple, List\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-29T08:38:19.014204Z","iopub.execute_input":"2023-09-29T08:38:19.014595Z","iopub.status.idle":"2023-09-29T08:38:19.022270Z","shell.execute_reply.started":"2023-09-29T08:38:19.014552Z","shell.execute_reply":"2023-09-29T08:38:19.021249Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"class config:\n    batch_size = 16\n    num_workers = 1\n    epochs = 200\n    hidden_units = 20","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.026006Z","iopub.execute_input":"2023-09-29T08:38:19.026365Z","iopub.status.idle":"2023-09-29T08:38:19.032675Z","shell.execute_reply.started":"2023-09-29T08:38:19.026341Z","shell.execute_reply":"2023-09-29T08:38:19.031696Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"markdown","source":"#### Utilizing GPUs","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.034123Z","iopub.execute_input":"2023-09-29T08:38:19.034706Z","iopub.status.idle":"2023-09-29T08:38:19.044710Z","shell.execute_reply.started":"2023-09-29T08:38:19.034672Z","shell.execute_reply":"2023-09-29T08:38:19.043894Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"df_non_covid = pd.read_csv('/kaggle/input/covid19-china/NonCOVID-CT-MetaInfo.csv')\ndf_covid = pd.read_csv('/kaggle/input/covid19-china/COVID-CT-MetaInfo.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.045959Z","iopub.execute_input":"2023-09-29T08:38:19.046220Z","iopub.status.idle":"2023-09-29T08:38:19.090902Z","shell.execute_reply.started":"2023-09-29T08:38:19.046198Z","shell.execute_reply":"2023-09-29T08:38:19.089844Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"df_covid.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.092264Z","iopub.execute_input":"2023-09-29T08:38:19.093305Z","iopub.status.idle":"2023-09-29T08:38:19.107083Z","shell.execute_reply.started":"2023-09-29T08:38:19.093270Z","shell.execute_reply":"2023-09-29T08:38:19.105819Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 350 entries, 0 to 349\nData columns (total 11 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   File name        349 non-null    object\n 1   Patient ID       349 non-null    object\n 2   Age              169 non-null    object\n 3   Gender           137 non-null    object\n 4   Location         228 non-null    object\n 5   Medical history  44 non-null     object\n 6   Time             134 non-null    object\n 7   Severity         178 non-null    object\n 8   Other diseases   19 non-null     object\n 9   DOI              203 non-null    object\n 10  Captions         337 non-null    object\ndtypes: object(11)\nmemory usage: 30.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_non_covid.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.108443Z","iopub.execute_input":"2023-09-29T08:38:19.109656Z","iopub.status.idle":"2023-09-29T08:38:19.125003Z","shell.execute_reply.started":"2023-09-29T08:38:19.109618Z","shell.execute_reply":"2023-09-29T08:38:19.123817Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 397 entries, 0 to 396\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  397 non-null    int64 \n 1   image name  397 non-null    object\n 2   patient id  397 non-null    object\ndtypes: int64(1), object(2)\nmemory usage: 9.4+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Data transformation and augmentation","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/covid19-china'","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.126505Z","iopub.execute_input":"2023-09-29T08:38:19.127444Z","iopub.status.idle":"2023-09-29T08:38:19.136838Z","shell.execute_reply.started":"2023-09-29T08:38:19.127420Z","shell.execute_reply":"2023-09-29T08:38:19.135830Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"train_transformer = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop((256), scale=(0.5,1)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])\n\nval_transformer = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(256),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.141654Z","iopub.execute_input":"2023-09-29T08:38:19.142755Z","iopub.status.idle":"2023-09-29T08:38:19.150909Z","shell.execute_reply.started":"2023-09-29T08:38:19.142717Z","shell.execute_reply":"2023-09-29T08:38:19.149992Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"data = datasets.ImageFolder(root=data_dir, # target folder of images\n                                  transform=val_transformer, # transforms to perform on data (images)\n                                  target_transform=None) # transforms to perform on labels (if necessary)\n\nprint(f\"Train data:\\n{data}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.152380Z","iopub.execute_input":"2023-09-29T08:38:19.152944Z","iopub.status.idle":"2023-09-29T08:38:19.201510Z","shell.execute_reply.started":"2023-09-29T08:38:19.152905Z","shell.execute_reply":"2023-09-29T08:38:19.200406Z"},"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"Train data:\nDataset ImageFolder\n    Number of datapoints: 746\n    Root location: /kaggle/input/covid19-china\n    StandardTransform\nTransform: Compose(\n               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n               CenterCrop(size=(256, 256))\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )\n","output_type":"stream"}]},{"cell_type":"code","source":"# class_names = train_data.classes\n# class_dict = train_data.class_to_idx\n\n# img, label = train_data[0][0], train_data[0][1]\n\n# img_permute = img.permute(1, 2, 0)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.204588Z","iopub.execute_input":"2023-09-29T08:38:19.205301Z","iopub.status.idle":"2023-09-29T08:38:19.211021Z","shell.execute_reply.started":"2023-09-29T08:38:19.205258Z","shell.execute_reply":"2023-09-29T08:38:19.209898Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":"### Train test split","metadata":{}},{"cell_type":"code","source":"train_percent = 0.9\n\ntrain_size = int(train_percent * len(data))\ntest_size = len(data) - train_size\n\ntrain_dataset, test_dataset = random_split(data, [train_size, test_size])\n\ntrain_dataset.dataset = datasets.ImageFolder(\n    root=train_dataset.dataset.root,\n    transform=train_transformer,\n    target_transform=train_dataset.dataset.target_transform\n)\n\ntrain_dataset.dataset, test_dataset.dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.216582Z","iopub.execute_input":"2023-09-29T08:38:19.217053Z","iopub.status.idle":"2023-09-29T08:38:19.237543Z","shell.execute_reply.started":"2023-09-29T08:38:19.217015Z","shell.execute_reply":"2023-09-29T08:38:19.236407Z"},"trusted":true},"execution_count":160,"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"(Dataset ImageFolder\n     Number of datapoints: 746\n     Root location: /kaggle/input/covid19-china\n     StandardTransform\n Transform: Compose(\n                Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n                RandomResizedCrop(size=(256, 256), scale=(0.5, 1), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n                RandomHorizontalFlip(p=0.5)\n                ToTensor()\n                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n            ),\n Dataset ImageFolder\n     Number of datapoints: 746\n     Root location: /kaggle/input/covid19-china\n     StandardTransform\n Transform: Compose(\n                Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n                CenterCrop(size=(256, 256))\n                ToTensor()\n                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n            ))"},"metadata":{}}]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=False)\n\nprint(f\"Number of samples in training set: {len(train_dataset)}\")\nprint(f\"Number of samples in testing set: {len(test_dataset)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.239321Z","iopub.execute_input":"2023-09-29T08:38:19.239971Z","iopub.status.idle":"2023-09-29T08:38:19.247729Z","shell.execute_reply.started":"2023-09-29T08:38:19.239925Z","shell.execute_reply":"2023-09-29T08:38:19.246456Z"},"trusted":true},"execution_count":161,"outputs":[{"name":"stdout","text":"Number of samples in training set: 671\nNumber of samples in testing set: 75\n","output_type":"stream"}]},{"cell_type":"code","source":"img, label = next(iter(train_loader))\n\nprint(img.shape, label.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:19.249686Z","iopub.execute_input":"2023-09-29T08:38:19.250479Z","iopub.status.idle":"2023-09-29T08:38:19.815554Z","shell.execute_reply.started":"2023-09-29T08:38:19.250439Z","shell.execute_reply":"2023-09-29T08:38:19.814208Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"torch.Size([16, 3, 256, 256]) torch.Size([16])\n","output_type":"stream"}]},{"cell_type":"code","source":"class ConvModel(nn.Module):\n    def __init__(self, input_shape, output_shape, hidden_units):\n        super().__init__()\n        \n        self.block_1 = nn.Sequential(\n                                nn.Conv2d(in_channels = input_shape,\n                                         out_channels = hidden_units,\n                                         kernel_size = 3,\n                                         stride = 1,\n                                         padding = 1),\n                                nn.ReLU(),\n                                nn.Conv2d(in_channels = hidden_units,\n                                        out_channels = hidden_units,\n                                        kernel_size = 3,\n                                        stride = 1,\n                                        padding = 1),\n                                nn.ReLU(),\n                                nn.MaxPool2d(kernel_size = 2,\n                                            stride = 2),\n#                                 nn.BatchNorm2d()\n        )\n        \n        self.block_2 = nn.Sequential(\n                                nn.Conv2d(hidden_units, hidden_units, 3, padding = 1),\n                                nn.ReLU(),\n                                nn.Conv2d(hidden_units, hidden_units, 3, padding = 1),\n                                nn.ReLU(),\n                                nn.MaxPool2d(2),\n#                                 nn.BatchNorm2d()\n        )\n        \n        self.block_3 = nn.Sequential(\n                                nn.Conv2d(hidden_units, hidden_units, 3, padding = 1),\n                                nn.ReLU(),\n                                nn.Conv2d(hidden_units, hidden_units, 3, padding = 1),\n                                nn.ReLU(),\n                                nn.MaxPool2d(2),\n#                                 nn.BatchNorm2d()\n        )\n        \n        self.block_4 = nn.Sequential(\n                                nn.Conv2d(hidden_units, hidden_units, 3, padding = 1),\n                                nn.ReLU(),\n                                nn.Conv2d(hidden_units, hidden_units, 3, padding = 1),\n                                nn.ReLU(),\n                                nn.MaxPool2d(2),\n#                                 nn.BatchNorm2d()\n        )\n        \n        self.classifier = nn.Sequential(\n                                nn.Flatten(),\n                                nn.Linear(in_features = 5120, out_features = output_shape))\n        \n        \n    def forward(self, x):\n        x = self.block_1(x)\n        x = self.block_2(x)\n        x = self.block_3(x)\n        x = self.block_4(x)\n#         print(x.shape)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:51.247278Z","iopub.execute_input":"2023-09-29T08:38:51.247613Z","iopub.status.idle":"2023-09-29T08:38:51.257416Z","shell.execute_reply.started":"2023-09-29T08:38:51.247585Z","shell.execute_reply":"2023-09-29T08:38:51.256326Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"model = ConvModel(input_shape=3, hidden_units=config.hidden_units, output_shape = 1)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:53.740745Z","iopub.execute_input":"2023-09-29T08:38:53.741438Z","iopub.status.idle":"2023-09-29T08:38:53.753578Z","shell.execute_reply.started":"2023-09-29T08:38:53.741406Z","shell.execute_reply":"2023-09-29T08:38:53.752406Z"},"trusted":true},"execution_count":173,"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"ConvModel(\n  (block_1): Sequential(\n    (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block_2): Sequential(\n    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block_3): Sequential(\n    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block_4): Sequential(\n    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=5120, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:54.425358Z","iopub.execute_input":"2023-09-29T08:38:54.425711Z","iopub.status.idle":"2023-09-29T08:38:54.431478Z","shell.execute_reply.started":"2023-09-29T08:38:54.425682Z","shell.execute_reply":"2023-09-29T08:38:54.430370Z"},"trusted":true},"execution_count":174,"outputs":[{"name":"stdout","text":"ConvModel(\n  (block_1): Sequential(\n    (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block_2): Sequential(\n    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block_3): Sequential(\n    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (block_4): Sequential(\n    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=5120, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = ConvModel(input_shape=3, hidden_units=10, output_shape = 1)\n\n# model_path = '/kaggle/input/cnn-models/model_cnn_proj_version_2.pt'\n# model.load_state_dict(torch.load(f=model_path))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:54.843244Z","iopub.execute_input":"2023-09-29T08:38:54.843606Z","iopub.status.idle":"2023-09-29T08:38:54.847810Z","shell.execute_reply.started":"2023-09-29T08:38:54.843578Z","shell.execute_reply":"2023-09-29T08:38:54.846910Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n              train_loader: torch.utils.data.DataLoader,\n              device,\n              loss_fn: torch.nn.Module,\n              optimizer: torch.optim.Optimizer,\n              train_loss):\n\n    for batch, (X,y) in enumerate(train_loader):\n\n        X, y = X.to(device), y.to(device)\n        model.train()\n        y_logits = model(X).squeeze()\n        y_pred = torch.round(torch.sigmoid(y_logits))\n        loss = loss_fn(y_pred, y.float())\n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:55.092513Z","iopub.execute_input":"2023-09-29T08:38:55.092851Z","iopub.status.idle":"2023-09-29T08:38:55.098832Z","shell.execute_reply.started":"2023-09-29T08:38:55.092822Z","shell.execute_reply":"2023-09-29T08:38:55.097794Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"def val_step(model: torch.nn.Module,\n            val_loader: torch.utils.data.DataLoader,\n            device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.inference_mode():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).squeeze()\n            preds = torch.round(torch.sigmoid(outputs))\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n    return all_labels, all_preds\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:55.448925Z","iopub.execute_input":"2023-09-29T08:38:55.449292Z","iopub.status.idle":"2023-09-29T08:38:55.455627Z","shell.execute_reply.started":"2023-09-29T08:38:55.449265Z","shell.execute_reply":"2023-09-29T08:38:55.454543Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"def train(model, data, train_dataset, epochs, device):\n\n    loss_fn = nn.BCELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n    accuracies = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n\n    for fold, (train_indices, val_indices) in enumerate(skf.split(train_dataset.dataset.imgs, train_dataset.dataset.targets), start=1):\n        print(f\"Fold {fold}\")\n        train_dataset = torch.utils.data.Subset(data, train_indices)\n        val_dataset = torch.utils.data.Subset(data, val_indices)\n\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n        torch.manual_seed(42)\n        epochs = epochs\n\n        for epoch in tqdm(range(epochs)):\n    #         print(f'Epoch: {epoch} \\n----------------')\n            train_loss = 0\n            train_step(model, train_loader, device, loss_fn, optimizer, train_loss)\n\n        train_loss /= len(train_loader)\n\n        all_labels, all_preds = val_step(model, val_loader, device)\n\n        accuracy = accuracy_score(all_labels, all_preds)\n        precision = precision_score(all_labels, all_preds)\n        recall = recall_score(all_labels, all_preds)\n        f1 = f1_score(all_labels, all_preds)\n\n        accuracies.append(accuracy)\n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n\n    avg_accuracy = np.mean(accuracies)\n    avg_precision = np.mean(precisions)\n    avg_recall = np.mean(recalls)\n    avg_f1 = np.mean(f1_scores)\n\n    print(f'Average Accuracy: {avg_accuracy}')\n    print(f\"Average Precision: {avg_precision}\")\n    print(f\"Average Recall: {avg_recall}\")\n    print(f\"Average F1 Score: {avg_f1}\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:55.794138Z","iopub.execute_input":"2023-09-29T08:38:55.794816Z","iopub.status.idle":"2023-09-29T08:38:55.805283Z","shell.execute_reply.started":"2023-09-29T08:38:55.794784Z","shell.execute_reply":"2023-09-29T08:38:55.804068Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader, device):\n    test_pred = []\n    test_labels = []\n    model.eval()\n    with torch.inference_mode():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).squeeze()\n            preds = torch.round(torch.sigmoid(outputs))\n            test_pred.extend(preds.cpu().numpy())\n            test_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(test_labels, test_pred)\n    precision = precision_score(test_labels, test_pred)\n    recall = recall_score(test_labels, test_pred)\n    f1 = f1_score(test_labels, test_pred)\n\n    print(accuracy)\n    print(precision)\n    print(recall)\n    print(f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:56.119896Z","iopub.execute_input":"2023-09-29T08:38:56.120243Z","iopub.status.idle":"2023-09-29T08:38:56.126768Z","shell.execute_reply.started":"2023-09-29T08:38:56.120218Z","shell.execute_reply":"2023-09-29T08:38:56.125814Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"print('Training the model')\ntrain(model, data, train_dataset, config.epochs, device)\nprint('testing the model')\ntest(model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:56.448575Z","iopub.execute_input":"2023-09-29T08:38:56.449008Z","iopub.status.idle":"2023-09-29T09:59:43.114168Z","shell.execute_reply.started":"2023-09-29T08:38:56.448976Z","shell.execute_reply":"2023-09-29T09:59:43.112964Z"},"trusted":true},"execution_count":180,"outputs":[{"name":"stdout","text":"Training the model\nFold 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c05fcfc8dea43da99ba142085ab4920"}},"metadata":{}},{"name":"stdout","text":"Fold 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e1a233a450a44f09a98a7532ca266b9"}},"metadata":{}},{"name":"stdout","text":"Fold 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e116169d5b94a42a56e4d61f5fddbea"}},"metadata":{}},{"name":"stdout","text":"Fold 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c25940f4949a4927bb322fdd4e0fd746"}},"metadata":{}},{"name":"stdout","text":"Fold 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a230852a9ae44b93b3f971d334427b8e"}},"metadata":{}},{"name":"stdout","text":"Average Accuracy: 0.5321700223713647\nAverage Precision: 0.5321700223713647\nAverage Recall: 1.0\nAverage F1 Score: 0.6946578997331948\ntesting the model\n0.6133333333333333\n0.6133333333333333\n1.0\n0.7603305785123966\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), f'cnn-custom-model-{config.epochs}-{config.hidden_units}.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.431676Z","iopub.status.idle":"2023-09-29T08:38:20.432040Z","shell.execute_reply.started":"2023-09-29T08:38:20.431870Z","shell.execute_reply":"2023-09-29T08:38:20.431895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# model.to(device)\n# print('testing the model')\n# test(model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.433854Z","iopub.status.idle":"2023-09-29T08:38:20.434565Z","shell.execute_reply.started":"2023-09-29T08:38:20.434315Z","shell.execute_reply":"2023-09-29T08:38:20.434339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torchvision.models as models\n\n# model_resnet = models.resnet50(pretrained=True)\n\n# for param in model_resnet.parameters():\n#     param.requires_grad = False\n\n# # Set the manual seeds\n# torch.manual_seed(42)\n# torch.cuda.manual_seed(42)\n\n# # Replace the classifier with a new one\n# model_resnet.fc = nn.Sequential(\n#     nn.Linear(2048, 512),  # Change the input size as per your model\n#     nn.ReLU(),\n#     nn.Dropout(0.5),  # Dropout layer to reduce overfitting\n#     nn.Linear(512, 1)  # Replace 'num_classes' with the number of your output classes\n# )\n\n# model_resnet.to(device);","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.435968Z","iopub.status.idle":"2023-09-29T08:38:20.436694Z","shell.execute_reply.started":"2023-09-29T08:38:20.436451Z","shell.execute_reply":"2023-09-29T08:38:20.436475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchinfo import summary\n\n# summary(model=model_resnet, \n#         input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n#         # col_names=[\"input_size\"], # uncomment for smaller output\n#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n#         col_width=20,\n#         row_settings=[\"var_names\"]\n# )","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.437961Z","iopub.status.idle":"2023-09-29T08:38:20.438645Z","shell.execute_reply.started":"2023-09-29T08:38:20.438398Z","shell.execute_reply":"2023-09-29T08:38:20.438431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.440098Z","iopub.status.idle":"2023-09-29T08:38:20.440783Z","shell.execute_reply.started":"2023-09-29T08:38:20.440555Z","shell.execute_reply":"2023-09-29T08:38:20.440578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.442047Z","iopub.status.idle":"2023-09-29T08:38:20.442731Z","shell.execute_reply.started":"2023-09-29T08:38:20.442500Z","shell.execute_reply":"2023-09-29T08:38:20.442523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.443974Z","iopub.status.idle":"2023-09-29T08:38:20.444655Z","shell.execute_reply.started":"2023-09-29T08:38:20.444425Z","shell.execute_reply":"2023-09-29T08:38:20.444448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # # Do a summary *after* freezing the features and changing the output classifier layer (uncomment for actual output)\n# summary(model_resnet, \n#         input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n#         verbose=0,\n#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n#         col_width=20,\n#         row_settings=[\"var_names\"]\n# )","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.445900Z","iopub.status.idle":"2023-09-29T08:38:20.446636Z","shell.execute_reply.started":"2023-09-29T08:38:20.446382Z","shell.execute_reply":"2023-09-29T08:38:20.446406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('Training the model')\n# train(model_resnet, data, train_dataset, config.epochs, device)\n# print('testing the model')\n# test(model_resnet, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.448113Z","iopub.status.idle":"2023-09-29T08:38:20.448789Z","shell.execute_reply.started":"2023-09-29T08:38:20.448558Z","shell.execute_reply":"2023-09-29T08:38:20.448580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracies, precisions, recalls, f1_scores","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.450039Z","iopub.status.idle":"2023-09-29T08:38:20.450716Z","shell.execute_reply.started":"2023-09-29T08:38:20.450475Z","shell.execute_reply":"2023-09-29T08:38:20.450498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.load(model_resnet.state_dict(), 'cnn-resnet-version-3.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.451900Z","iopub.status.idle":"2023-09-29T08:38:20.452587Z","shell.execute_reply.started":"2023-09-29T08:38:20.452330Z","shell.execute_reply":"2023-09-29T08:38:20.452352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Import/install Gradio \n# try:\n#     import gradio as gr\n# except: \n#     !pip -q install gradio\n#     import gradio as gr\n    \n# print(f\"Gradio version: {gr.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.453771Z","iopub.status.idle":"2023-09-29T08:38:20.454535Z","shell.execute_reply.started":"2023-09-29T08:38:20.454288Z","shell.execute_reply":"2023-09-29T08:38:20.454311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Tuple, Dict\n\ndef predict(img):\n    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n    \"\"\"\n    class_names = ['Covid']\n    # Transform the target image and add a batch dimension\n    img = val_transformer(img).unsqueeze(0)\n    img = img.to(device)\n    \n    # Put model into evaluation mode and turn on inference mode\n    model.eval()\n    with torch.inference_mode():\n        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n        pred_prob = torch.sigmoid(model(img))\n        \n    pred_probs = {'Covid' : float(pred_prob), 'Non Covid' : (1-float(pred_prob))}\n\n    # Return the prediction dictionary and prediction time \n    return pred_probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom PIL import Image\nimport numpy as np\n\n# Randomly select a test image path\nrandom_image_path = '/kaggle/input/covidct/CT_COVID/2020.02.10.20021584-p6-52%0.png'\n\n# Open the target image\nimage = Image.open(random_image_path)\nprint(f\"[INFO] Predicting on image at path: {random_image_path}\\n\")\n\n# Predict on the target image and print out the outputs\npred_dict = predict(image)\nprint(f\"Prediction label and probability dictionary: \\n{pred_dict}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.array(image)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.459698Z","iopub.status.idle":"2023-09-29T08:38:20.460386Z","shell.execute_reply.started":"2023-09-29T08:38:20.460155Z","shell.execute_reply":"2023-09-29T08:38:20.460179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Create a list of example inputs to our Gradio demo\n# example_list = ['/kaggle/input/covid19-china/CT_NonCOVID/CT_NonCOVID/10%2.jpg',\n#                '/kaggle/input/covid19-china/CT_NonCOVID/CT_NonCOVID/1030.png',\n#                '/kaggle/input/covid19-china/CT_NonCOVID/CT_NonCOVID/1029.png']\n# example_list","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.461616Z","iopub.status.idle":"2023-09-29T08:38:20.462278Z","shell.execute_reply.started":"2023-09-29T08:38:20.462058Z","shell.execute_reply":"2023-09-29T08:38:20.462080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def deploy():\n#     # Create title, description and article strings\n#     title = \"Corona Prediction\"\n#     description = \"A Convolutional Neural Network To classify whether a person have Corona or not using CT  Scans.\"\n#     article = \"Created by Thenujan Nagaratnam for DNN module at UoM\"\n\n#     # Create the Gradio demo\n#     demo = gr.Interface(fn=predict, # mapping function from input to output\n#                         inputs=gr.Image(type=\"pil\"), # what are the inputs?\n#                         outputs=[gr.Label(num_top_classes=2, label=\"Predictions\")], # our fn has two outputs, therefore we have two outputs\n#                         examples=example_list, \n#                         title=title,\n#                         description=description,\n#                         article=article)\n\n#     # Launch the demo!\n#     demo.launch(debug=True, # print errors locally?\n#                 share=True) # generate a publically shareable URL?","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.463490Z","iopub.status.idle":"2023-09-29T08:38:20.464176Z","shell.execute_reply.started":"2023-09-29T08:38:20.463944Z","shell.execute_reply":"2023-09-29T08:38:20.463965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# deploy()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.465396Z","iopub.status.idle":"2023-09-29T08:38:20.466113Z","shell.execute_reply.started":"2023-09-29T08:38:20.465834Z","shell.execute_reply":"2023-09-29T08:38:20.465871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install gradio_client","metadata":{"execution":{"iopub.status.busy":"2023-09-29T11:33:19.136471Z","iopub.execute_input":"2023-09-29T11:33:19.136797Z","iopub.status.idle":"2023-09-29T11:33:29.904764Z","shell.execute_reply.started":"2023-09-29T11:33:19.136771Z","shell.execute_reply":"2023-09-29T11:33:29.903522Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gradio_client\n  Downloading gradio_client-0.5.3-py3-none-any.whl (298 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio_client) (2023.9.0)\nCollecting httpx (from gradio_client)\n  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from gradio_client) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio_client) (21.3)\nRequirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio_client) (2.31.0)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio_client) (4.6.3)\nRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio_client) (11.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio_client) (3.12.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio_client) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio_client) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->gradio_client) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio_client) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio_client) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio_client) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio_client) (2023.7.22)\nCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio_client)\n  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio_client) (1.3.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio_client) (3.7.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio_client) (0.14.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio_client) (1.1.1)\nInstalling collected packages: httpcore, httpx, gradio_client\nSuccessfully installed gradio_client-0.5.3 httpcore-0.18.0 httpx-0.25.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from gradio_client import Client\nimport json\n\nclient = Client(\"https://thenujan-covid-cnn.hf.space/\")\nresult = client.predict(\n                '/kaggle/input/covid19-china/CT_NonCOVID/CT_NonCOVID/10%2.jpg',\t# str (filepath or URL to image) in 'img' Image component\n                api_name=\"/predict\"\n)\n\nwith open(result, 'r') as json_file:\n    data = json.load(json_file)\n\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T11:33:29.906991Z","iopub.execute_input":"2023-09-29T11:33:29.907354Z","iopub.status.idle":"2023-09-29T11:33:31.282843Z","shell.execute_reply.started":"2023-09-29T11:33:29.907317Z","shell.execute_reply":"2023-09-29T11:33:31.281856Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Loaded as API: https://thenujan-covid-cnn.hf.space/ ✔\n{'label': 'Covid', 'confidences': [{'label': 'Covid', 'confidence': 0.500697672367096}, {'label': 'Non Covid', 'confidence': 0.49930232763290405}]}\n","output_type":"stream"}]},{"cell_type":"code","source":"# from gradio_client import Client\n\n# client = Client(\"https://thenujan-vpr-deploy.hf.space/\")\n# result = client.predict(\n# \t\t\t\t\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\",\t# str (filepath or URL to image) in 'image' Image component\n# \t\t\t\tapi_name=\"/predict\"\n# )\n# print(result)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T11:35:11.284151Z","iopub.execute_input":"2023-09-29T11:35:11.284478Z","iopub.status.idle":"2023-09-29T11:35:21.763376Z","shell.execute_reply.started":"2023-09-29T11:35:11.284445Z","shell.execute_reply":"2023-09-29T11:35:21.762463Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Loaded as API: https://thenujan-vpr-deploy.hf.space/ ✔\n/tmp/gradio/tmpcvmyph02.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# with open(result, 'r') as json_file:\n#     data = json.load(json_file)\n\n# print(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T11:39:23.349875Z","iopub.execute_input":"2023-09-29T11:39:23.350218Z","iopub.status.idle":"2023-09-29T11:39:23.354178Z","shell.execute_reply.started":"2023-09-29T11:39:23.350189Z","shell.execute_reply":"2023-09-29T11:39:23.353143Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# data['similar_image_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2023-09-29T11:39:25.703926Z","iopub.execute_input":"2023-09-29T11:39:25.704267Z","iopub.status.idle":"2023-09-29T11:39:25.708933Z","shell.execute_reply.started":"2023-09-29T11:39:25.704236Z","shell.execute_reply":"2023-09-29T11:39:25.707339Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# pip install open-clip-torch","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.470986Z","iopub.status.idle":"2023-09-29T08:38:20.471640Z","shell.execute_reply.started":"2023-09-29T08:38:20.471390Z","shell.execute_reply":"2023-09-29T08:38:20.471421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import open_clip\n\n# model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:Thenujan/ViT-H-14')\n# tokenizer = open_clip.get_tokenizer('hf-hub:Thenujan/ViT-H-14')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.472837Z","iopub.status.idle":"2023-09-29T08:38:20.473490Z","shell.execute_reply.started":"2023-09-29T08:38:20.473259Z","shell.execute_reply":"2023-09-29T08:38:20.473280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.474650Z","iopub.status.idle":"2023-09-29T08:38:20.475320Z","shell.execute_reply.started":"2023-09-29T08:38:20.475090Z","shell.execute_reply":"2023-09-29T08:38:20.475112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch as th\n# backbone = open_clip.create_model_and_transforms('ViT-H-14', None)[0].visual\n# backbone.load_state_dict(th.load('https://huggingface.co/Thenujan/ViT-H-14/main/model.bin'))  #https://huggingface.co/hca97/aicrowd-visual-recognition-models/blob/main/model1.pt\n# # backbone, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:Thenujan/ViT-H-14')\n# backbone.eval()   # Dropping unecessary layers","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.476659Z","iopub.status.idle":"2023-09-29T08:38:20.477359Z","shell.execute_reply.started":"2023-09-29T08:38:20.477127Z","shell.execute_reply":"2023-09-29T08:38:20.477150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import open_clip\n\n# model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:Thenujan/ViT-H-14')\n# tokenizer = open_clip.get_tokenizer('hf-hub:Thenujan/ViT-H-14')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.478545Z","iopub.status.idle":"2023-09-29T08:38:20.479232Z","shell.execute_reply.started":"2023-09-29T08:38:20.479003Z","shell.execute_reply":"2023-09-29T08:38:20.479026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# costom model with 3 layers, 60 epochs, hidden units 10\n#     Average Accuracy: 0.5549709172259508\n#     Average Precision: 0.5552134116025019\n#     Average Recall: 0.8262974683544304\n#     Average F1 Score: 0.6637566887530646\n#     testing the model\n#     0.5333333333333333\n#     0.5333333333333333\n#     0.8205128205128205\n#     0.6464646464646464\n\n# costom model with 3 layers, 200 epochs, hidden units 10\n#     Average Accuracy: 0.5321700223713647\n#     Average Precision: 0.5321700223713647\n#     Average Recall: 1.0\n#     Average F1 Score: 0.6946578997331948\n#     testing the model\n#     0.5333333333333333\n#     0.5333333333333333\n#     1.0\n#     0.6956521739130436\n\n# custom model with 5 layers, 200 epochs, hidden units 10\n#     Average Accuracy: 0.5321700223713647\n#     Average Precision: 0.5321700223713647\n#     Average Recall: 1.0\n#     Average F1 Score: 0.6946578997331948\n#     testing the model\n#     0.6133333333333333\n#     0.6133333333333333\n#     1.0\n#     0.7603305785123966\n\n# custom model with 5 layers, 200 epochs, hidden units 20\n#     Average Accuracy: 0.5321700223713647\n#     Average Precision: 0.5321700223713647\n#     Average Recall: 1.0\n#     Average F1 Score: 0.6946578997331948\n#     testing the model\n#     0.6133333333333333\n#     0.6133333333333333\n#     1.0\n#     0.7603305785123966","metadata":{"execution":{"iopub.status.busy":"2023-09-29T08:38:20.480456Z","iopub.status.idle":"2023-09-29T08:38:20.481122Z","shell.execute_reply.started":"2023-09-29T08:38:20.480893Z","shell.execute_reply":"2023-09-29T08:38:20.480916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install open-clip-torch","metadata":{"execution":{"iopub.status.busy":"2023-09-29T10:08:51.336227Z","iopub.execute_input":"2023-09-29T10:08:51.337005Z","iopub.status.idle":"2023-09-29T10:09:00.575220Z","shell.execute_reply.started":"2023-09-29T10:08:51.336969Z","shell.execute_reply":"2023-09-29T10:09:00.573918Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"Collecting open-clip-torch\n  Downloading open_clip_torch-2.20.0-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.15.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2023.6.3)\nCollecting ftfy (from open-clip-torch)\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (4.66.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.16.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.1.99)\nRequirement already satisfied: protobuf<4 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (3.20.3)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.9.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.2)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->open-clip-torch) (0.2.6)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (21.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open-clip-torch) (0.3.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open-clip-torch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\nInstalling collected packages: ftfy, open-clip-torch\nSuccessfully installed ftfy-6.1.1 open-clip-torch-2.20.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import open_clip\n\n# model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n# tokenizer = open_clip.get_tokenizer('hf-hub:laion/CLIP-ViT-H-14-laion2B-s32B-b79K')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T10:30:27.531584Z","iopub.execute_input":"2023-09-29T10:30:27.531987Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)ip_pytorch_model.bin:   0%|          | 0.00/3.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aecc5d78cb11456788fe0e3c797a78d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)pen_clip_config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c43b8672324009b5c8fcf7a668ce34"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}