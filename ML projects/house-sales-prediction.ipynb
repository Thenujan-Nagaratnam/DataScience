{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-05T12:50:09.643767Z","iopub.execute_input":"2023-05-05T12:50:09.644546Z","iopub.status.idle":"2023-05-05T12:50:09.654129Z","shell.execute_reply.started":"2023-05-05T12:50:09.644504Z","shell.execute_reply":"2023-05-05T12:50:09.653042Z"},"trusted":true},"execution_count":398,"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv')\ntest = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv')\nsample = pd.read_csv('/kaggle/input/home-data-for-ml-course/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.659406Z","iopub.execute_input":"2023-05-05T12:50:09.660057Z","iopub.status.idle":"2023-05-05T12:50:09.715321Z","shell.execute_reply.started":"2023-05-05T12:50:09.660011Z","shell.execute_reply":"2023-05-05T12:50:09.714324Z"},"trusted":true},"execution_count":399,"outputs":[]},{"cell_type":"code","source":"num_cols = train.select_dtypes(include=['int', 'float']).columns\nnum_cols","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.720064Z","iopub.execute_input":"2023-05-05T12:50:09.720698Z","iopub.status.idle":"2023-05-05T12:50:09.729828Z","shell.execute_reply.started":"2023-05-05T12:50:09.720659Z","shell.execute_reply":"2023-05-05T12:50:09.728523Z"},"trusted":true},"execution_count":400,"outputs":[{"execution_count":400,"output_type":"execute_result","data":{"text/plain":"Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n       'MiscVal', 'MoSold', 'YrSold', 'SalePrice'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"numeric_features = ['OverallQual', 'GrLivArea', 'GarageCars',\n                    '2ndFlrSF', 'TotalBsmtSF', 'YearBuilt',\n                    'BsmtFinSF1', 'Fireplaces', 'LotArea',\n                    'OverallCond', 'ScreenPorch', 'YearRemodAdd', \n                    'HalfBath', '1stFlrSF','BsmtFullBath', \n                    'BsmtHalfBath', 'FullBath', 'BedroomAbvGr']","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.731407Z","iopub.execute_input":"2023-05-05T12:50:09.731840Z","iopub.status.idle":"2023-05-05T12:50:09.742964Z","shell.execute_reply.started":"2023-05-05T12:50:09.731782Z","shell.execute_reply":"2023-05-05T12:50:09.741362Z"},"trusted":true},"execution_count":401,"outputs":[]},{"cell_type":"code","source":"# train['TotalBsmtSF'].value_counts().sort_index() , 'BedroomAbvGr'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.745570Z","iopub.execute_input":"2023-05-05T12:50:09.745944Z","iopub.status.idle":"2023-05-05T12:50:09.756937Z","shell.execute_reply.started":"2023-05-05T12:50:09.745913Z","shell.execute_reply":"2023-05-05T12:50:09.755932Z"},"trusted":true},"execution_count":402,"outputs":[]},{"cell_type":"code","source":"# train['BedroomAbvGr'].value_counts().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.758617Z","iopub.execute_input":"2023-05-05T12:50:09.759433Z","iopub.status.idle":"2023-05-05T12:50:09.770556Z","shell.execute_reply.started":"2023-05-05T12:50:09.759386Z","shell.execute_reply":"2023-05-05T12:50:09.769272Z"},"trusted":true},"execution_count":403,"outputs":[]},{"cell_type":"code","source":"def remove_outliers(X, y):\n    data = pd.concat([X, y], axis=1)\n    \n    data = data.drop(data['GrLivArea'][data['GrLivArea'] > 4500].index)\n    data = data.drop(data['TotalBsmtSF'][data['TotalBsmtSF'] > 2500].index)\n    data = data.drop(data['LotArea'][data['LotArea'] > 50000].index)\n    data = data.drop(data['BsmtFinSF1'][data['BsmtFinSF1'] > 2500].index)\n    data = data.drop(data['1stFlrSF'][data['1stFlrSF'] > 3000].index)\n#     data = data.drop(data['ScreenPorch'][data['ScreenPorch'] > 450].index)    \n    data = data.drop(data['TotalBsmtSF'][data['TotalBsmtSF'] > 3000].index)\n    \n    new_y = data.pop('SalePrice')\n    new_X = data\n    return new_X, new_y","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.772753Z","iopub.execute_input":"2023-05-05T12:50:09.773201Z","iopub.status.idle":"2023-05-05T12:50:09.785080Z","shell.execute_reply.started":"2023-05-05T12:50:09.773162Z","shell.execute_reply":"2023-05-05T12:50:09.783529Z"},"trusted":true},"execution_count":404,"outputs":[]},{"cell_type":"code","source":"bad_cat_features = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']\n\n# Remove bad features\nother_cat_features = train.select_dtypes(include='O').columns.tolist()\nfor col in bad_cat_features:\n    other_cat_features.remove(col)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.787848Z","iopub.execute_input":"2023-05-05T12:50:09.788507Z","iopub.status.idle":"2023-05-05T12:50:09.801555Z","shell.execute_reply.started":"2023-05-05T12:50:09.788421Z","shell.execute_reply":"2023-05-05T12:50:09.800211Z"},"trusted":true},"execution_count":405,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\ndef score_data(X, y, random_state=42):\n    l_model = LinearRegression()\n    rf_model = RandomForestRegressor(random_state=random_state)\n    gb_model = GradientBoostingRegressor(random_state=random_state)\n    \n    l_score = -1 * cross_val_score(l_model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1).mean()\n    rf_score = -1 * cross_val_score(rf_model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1).mean()\n    gb_score = -1 * cross_val_score(gb_model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1).mean()\n    \n    print(f'Data score:\\nLinear regression: {l_score}\\nRandom forest: {rf_score}\\nGradient boosting: {gb_score}')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.804719Z","iopub.execute_input":"2023-05-05T12:50:09.805368Z","iopub.status.idle":"2023-05-05T12:50:09.814027Z","shell.execute_reply.started":"2023-05-05T12:50:09.805316Z","shell.execute_reply":"2023-05-05T12:50:09.812875Z"},"trusted":true},"execution_count":406,"outputs":[]},{"cell_type":"code","source":"# numeric_features","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.816059Z","iopub.execute_input":"2023-05-05T12:50:09.817505Z","iopub.status.idle":"2023-05-05T12:50:09.831656Z","shell.execute_reply.started":"2023-05-05T12:50:09.817422Z","shell.execute_reply":"2023-05-05T12:50:09.830504Z"},"trusted":true},"execution_count":407,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='most_frequent')\ntrain_data_for_imput = pd.concat([train[numeric_features], train[other_cat_features]], axis=1)\ntest_data_for_imput = pd.concat([test[numeric_features], test[other_cat_features]], axis=1)\n\nimputed_train_data = pd.DataFrame(data=imputer.fit_transform(train_data_for_imput), \n                                  index=train.index, \n                                  columns=train_data_for_imput.columns)\nimputed_test_data = pd.DataFrame(data=imputer.transform(test_data_for_imput), \n                                 index=test.index, \n                                 columns=test_data_for_imput.columns)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.845616Z","iopub.execute_input":"2023-05-05T12:50:09.846050Z","iopub.status.idle":"2023-05-05T12:50:09.900935Z","shell.execute_reply.started":"2023-05-05T12:50:09.846012Z","shell.execute_reply":"2023-05-05T12:50:09.899699Z"},"trusted":true},"execution_count":408,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nOHE = OneHotEncoder(sparse=False)\ntrain_ohe_df = pd.DataFrame(data=OHE.fit_transform(imputed_train_data[other_cat_features]), \n                            index=imputed_train_data.index)\ntest_ohe_df = pd.DataFrame(OHE.transform(imputed_test_data[other_cat_features]), \n                           index=imputed_test_data.index)\n\n# In the latest version sklearn raise FutureWarning if columns names aren't strings\ntrain_ohe_df.columns = train_ohe_df.columns.map(str)\ntest_ohe_df.columns = test_ohe_df.columns.map(str)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.902903Z","iopub.execute_input":"2023-05-05T12:50:09.903245Z","iopub.status.idle":"2023-05-05T12:50:09.973748Z","shell.execute_reply.started":"2023-05-05T12:50:09.903213Z","shell.execute_reply":"2023-05-05T12:50:09.972204Z"},"trusted":true},"execution_count":409,"outputs":[]},{"cell_type":"code","source":"train_X = pd.concat([imputed_train_data[numeric_features].astype('int32'), train_ohe_df], axis=1)\ntrain_y = train['SalePrice']\ntrain_X, train_y = remove_outliers(train_X, train_y)\n\ntest_X = pd.concat([imputed_test_data[numeric_features].astype('int32'), test_ohe_df], axis=1)\n\n# score_data(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:09.975365Z","iopub.execute_input":"2023-05-05T12:50:09.975747Z","iopub.status.idle":"2023-05-05T12:50:10.009556Z","shell.execute_reply.started":"2023-05-05T12:50:09.975712Z","shell.execute_reply":"2023-05-05T12:50:10.007886Z"},"trusted":true},"execution_count":410,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\n# Instantiate a StandardScaler object\nscaler = RobustScaler()\n\n# Scale the numeric features in train_X\ntrain_X[numeric_features] = scaler.fit_transform(train_X[numeric_features])\ntest_X[numeric_features] = scaler.transform(test_X[numeric_features])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.013293Z","iopub.execute_input":"2023-05-05T12:50:10.013713Z","iopub.status.idle":"2023-05-05T12:50:10.039232Z","shell.execute_reply.started":"2023-05-05T12:50:10.013675Z","shell.execute_reply":"2023-05-05T12:50:10.038179Z"},"trusted":true},"execution_count":411,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.040422Z","iopub.execute_input":"2023-05-05T12:50:10.041790Z","iopub.status.idle":"2023-05-05T12:50:10.049865Z","shell.execute_reply.started":"2023-05-05T12:50:10.041735Z","shell.execute_reply":"2023-05-05T12:50:10.048539Z"},"trusted":true},"execution_count":412,"outputs":[{"execution_count":412,"output_type":"execute_result","data":{"text/plain":"(1443, 252)"},"metadata":{}}]},{"cell_type":"code","source":"# from sklearn.decomposition import PCA\n# import matplotlib.pyplot as plt\n\n# # create a PCA object with desired number of components\n# pca = PCA(n_components=len(train_X.columns))\n\n# # fit the PCA model to the data\n# pca.fit(train_X)\n\n# # get the eigenvalues\n# eigenvalues = pca.explained_variance_\n\n# # create a scree plot\n# plt.plot(range(1, len(eigenvalues)+1), eigenvalues, 'o-', linewidth=2)\n# plt.xlabel('Principal Component')\n# plt.ylabel('Eigenvalue')\n# plt.title('Scree Plot')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.051317Z","iopub.execute_input":"2023-05-05T12:50:10.051951Z","iopub.status.idle":"2023-05-05T12:50:10.063017Z","shell.execute_reply.started":"2023-05-05T12:50:10.051910Z","shell.execute_reply":"2023-05-05T12:50:10.061645Z"},"trusted":true},"execution_count":413,"outputs":[]},{"cell_type":"code","source":"# from sklearn.decomposition import PCA\n# import matplotlib.pyplot as plt\n\n# # create a PCA object with maximum number of components\n# pca = PCA(n_components=len(train_X.columns))\n\n# # fit the PCA model to the data\n# pca.fit(train_X)\n\n# # get the eigenvalues\n# eigenvalues = pca.explained_variance_\n\n# # calculate the proportion of variance explained by each component\n# variance_proportions = eigenvalues / sum(eigenvalues)\n\n# # create a scree plot\n# plt.plot(range(1, len(eigenvalues)+1), variance_proportions, 'o-', linewidth=2)\n# plt.xlabel('Principal Component')\n# plt.ylabel('Proportion of Variance Explained')\n# plt.title('Scree Plot')\n# plt.show()\n\n# # calculate the cumulative proportion of variance explained\n# cumulative_variance = np.cumsum(variance_proportions)\n\n# # find the number of components that explain at least 95% of the variance\n# n_components = np.argmax(cumulative_variance >= 0.95) + 1\n# print(\"Number of components to explain at least 95% of the variance:\", n_components)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.064996Z","iopub.execute_input":"2023-05-05T12:50:10.065641Z","iopub.status.idle":"2023-05-05T12:50:10.082154Z","shell.execute_reply.started":"2023-05-05T12:50:10.065602Z","shell.execute_reply":"2023-05-05T12:50:10.080580Z"},"trusted":true},"execution_count":414,"outputs":[]},{"cell_type":"code","source":"# model = GradientBoostingRegressor(learning_rate = 0.1, max_depth =  3, n_estimators = 200, random_state=42)\n# model.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.084135Z","iopub.execute_input":"2023-05-05T12:50:10.084541Z","iopub.status.idle":"2023-05-05T12:50:10.099345Z","shell.execute_reply.started":"2023-05-05T12:50:10.084504Z","shell.execute_reply":"2023-05-05T12:50:10.097725Z"},"trusted":true},"execution_count":415,"outputs":[]},{"cell_type":"code","source":"# # Create a correlation matrix\n# corr_matrix = train_X.corr().abs()\n\n# # Set a threshold for dropping variables\n# threshold = 0.8\n\n# # Find variables with correlation greater than the threshold\n# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n# to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\n# # Drop the variables\n# train_X.drop(to_drop, axis=1, inplace=True)\n# test_X.drop(to_drop, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.100720Z","iopub.execute_input":"2023-05-05T12:50:10.101090Z","iopub.status.idle":"2023-05-05T12:50:10.112459Z","shell.execute_reply.started":"2023-05-05T12:50:10.101046Z","shell.execute_reply":"2023-05-05T12:50:10.111183Z"},"trusted":true},"execution_count":416,"outputs":[]},{"cell_type":"code","source":"# to_drop","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.116588Z","iopub.execute_input":"2023-05-05T12:50:10.117023Z","iopub.status.idle":"2023-05-05T12:50:10.124728Z","shell.execute_reply.started":"2023-05-05T12:50:10.116983Z","shell.execute_reply":"2023-05-05T12:50:10.123708Z"},"trusted":true},"execution_count":417,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n\n# # Concatenate the training features and outcome variable into a single DataFrame\n# train_df = pd.concat([train_X, train_y], axis=1)\n\n# # Set a threshold for dropping variables\n# threshold = 0.1\n\n# # Compute the correlation matrix with the outcome variable\n# corr_matrix = train_df.corr().abs()\n# corr_with_outcome = corr_matrix.iloc[:-1,-1]\n\n# # Find variables with correlation less than the threshold\n# to_drop = corr_with_outcome[corr_with_outcome < threshold].index\n\n# # Drop the variables from the training features\n# train_X.drop(to_drop, axis=1, inplace=True)\n# test_X.drop(to_drop, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:50:10.127378Z","iopub.execute_input":"2023-05-05T12:50:10.128528Z","iopub.status.idle":"2023-05-05T12:50:10.136768Z","shell.execute_reply.started":"2023-05-05T12:50:10.128473Z","shell.execute_reply":"2023-05-05T12:50:10.135749Z"},"trusted":true},"execution_count":418,"outputs":[]},{"cell_type":"code","source":"# from xgboost import XGBRegressor\n# from sklearn.metrics import mean_squared_error\n\n# # Create an instance of XGBRegressor with desired hyperparameters\n# model = XGBRegressor()\n\n# # Fit the model to the training data\n# model.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:54:50.390495Z","iopub.execute_input":"2023-05-05T12:54:50.391065Z","iopub.status.idle":"2023-05-05T12:54:51.583236Z","shell.execute_reply.started":"2023-05-05T12:54:50.391024Z","shell.execute_reply":"2023-05-05T12:54:51.582151Z"},"trusted":true},"execution_count":423,"outputs":[{"execution_count":423,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)"},"metadata":{}}]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\nmodel = CatBoostRegressor(n_estimators=10000, loss_function='RMSE',\n                              random_state=0, max_depth=5, \n                              verbose=False, subsample=0.5, random_strength=1.5)\nmodel.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:51:47.011559Z","iopub.execute_input":"2023-05-05T12:51:47.011908Z","iopub.status.idle":"2023-05-05T12:51:47.017285Z","shell.execute_reply.started":"2023-05-05T12:51:47.011875Z","shell.execute_reply":"2023-05-05T12:51:47.015897Z"},"trusted":true},"execution_count":420,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_X)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:51:47.019059Z","iopub.execute_input":"2023-05-05T12:51:47.020187Z","iopub.status.idle":"2023-05-05T12:51:47.178063Z","shell.execute_reply.started":"2023-05-05T12:51:47.020122Z","shell.execute_reply":"2023-05-05T12:51:47.177014Z"},"trusted":true},"execution_count":421,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'Id': test.Id,\n                       'SalePrice': y_pred})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:51:47.179513Z","iopub.execute_input":"2023-05-05T12:51:47.180547Z","iopub.status.idle":"2023-05-05T12:51:47.191167Z","shell.execute_reply.started":"2023-05-05T12:51:47.180502Z","shell.execute_reply":"2023-05-05T12:51:47.190172Z"},"trusted":true},"execution_count":422,"outputs":[]}]}